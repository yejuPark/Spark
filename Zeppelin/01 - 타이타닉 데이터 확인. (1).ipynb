{
  "metadata": {
    "name": "01 - 타이타닉 데이터 확인",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.appName(\"spark-dataframe\").getOrCreate()\nspark"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfilepath \u003d \"file:////home/ubuntu/working/spark-examples/data/titanic_train.csv\"\n\ntitanic_sdf \u003d spark.read.csv(filepath, inferSchema\u003dTrue, header\u003dTrue)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ntitanic_sdf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(titanic_sdf)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ntitanic_sdf.createOrReplaceTempView(\"titanic\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \"\"\"\n    SELECT * FROM titanic\n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### DataLake -\u003e DataWarehouse\n- survived, pclass, sex, age, Fare\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nquery \u003d \"\"\"\n    SELECT\n        t.Survived, t.Sex, t.Pclass, t.Fare, t.Age\n    FROM titanic t \n\"\"\"\n\ntitanic_wh \u003d spark.sql(query)\nz.show(titanic_wh)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntitanic_wh.createOrReplaceTempView(\"titanic\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## DataWarehouse -\u003e DataMart"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as F\n\n# 이상치 - Fare가 200 초과 제거\n\nq1 \u003d titanic_wh.approxQuantile(\"Fare\", [0.25], 0.05)[0]\nq3 \u003d titanic_wh.approxQuantile(\"Fare\", [0.75], 0.05)[0]\n\n# IQR 계산\niqr \u003d q3 - q1\n\n# 이상치 제거를 위한 상한선과 하한선 계산\nlower_bound \u003d q1 - 1.5 * iqr\nupper_bound \u003d q3 + 1.5 * iqr\n\nfiltered_df \u003d titanic_wh.filter((F.col(\"Fare\") \u003e\u003d lower_bound) \u0026 (F.col(\"Fare\") \u003c\u003d upper_bound))\nfiltered_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfiltered_df.createOrReplaceTempView(\"titanic\")"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic\n\"\"\"\n\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 결측치 확인 후 제거\n\nquery \u003d \"\"\"\n\n    SELECT *\n    FROM titanic\n    WHERE Age is not null\n      AND Survived is not null\n      AND Sex is not null\n      AND Pclass is not null\n      AND Fare !\u003d 0\n      AND Fare \u003c 200\n\"\"\"\ntitanic_result \u003d spark.sql(query)\nz.show(titanic_result)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 나이대 컬럼 추가\n\ndef age_grade(age):\n    age_grade \u003d int(age/10)*10\n    return age_grade"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.types import LongType\n\nspark.udf.register(\u0027age_grade\u0027, age_grade, LongType())"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nquery \u003d \"\"\"\n    SELECT\n        *, age_grade(Age) as Age_grade\n    FROM titanic\n\"\"\"\ntitanic_result \u003d spark.sql(query)\nz.show(titanic_result)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \n# DataMart\n\ntitanic_result.createOrReplaceTempView(\"titanic\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# EDA 계획\n\n- 생존한 남녀 수 비교 (count)\n- 남녀의 생존 비율\n- Pclass 별 Fare \n- Pclass 별 생존한 사람 수\n- 나이대 컬럼 생성해 나이대 별 생존한 사람 수"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 전체 남녀 수 비교 (count)\n\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic\n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 생존한 남녀 수 비교\n\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic\n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 남녀의 생존 비율\n# - Survived AVG : 생존은 1, 사망은 0 이므로 avg \u003d 생존한 사람 수 / 전체 사람 수 \u003d 1의 개수 / 전체 개수\n\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic\n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Pclass 별 Fare\n\nquery \u003d \"\"\"\n    SELECT t.Pclass, t.Fare\n    FROM titanic t\n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic \n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic \n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 나이대 생존 수\nquery \u003d \"\"\"\n    SELECT *\n    FROM titanic \n\"\"\"\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nspark.stop()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}